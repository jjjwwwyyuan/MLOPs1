# ğŸ‹ï¸â€â™€ï¸ MLOps HW2: Feature Store & ML Pipeline with Feast

This project demonstrates the use of **Feast** (Feature Store) integrated with a complete ML pipeline using data from `athletes.csv`. It includes feature versioning, model training, performance comparison, and carbon emissions tracking.

---

## ğŸ“ Project Structure

â”œâ”€â”€ MLOps HW2.ipynb # Main notebook (Colab-compatible)
â”œâ”€â”€ athletes_data.zip # Compressed dataset (replace athletes.csv)
â”œâ”€â”€ feature_repo/
â”‚ â”œâ”€â”€ feature_store.yaml # Feast configuration
â”‚ â””â”€â”€ feature_definition.py # FeatureView definitions (v1 and v2)
â””â”€â”€ README.md # This file

--

## âš™ï¸ Steps Performed

1. **Data Cleaning & Outlier Removal**
2. **Feature Engineering & Versioning**
    - `v1`: Basic features â€” age, height, weight, gender, region
    - `v2`: Engineered BMI with reduced feature set
3. **Feature Store Setup**
    - Initialized via `feast init`
    - Feature definitions created and applied via `feast apply`
4. **Model Training**
    - 4 experiments: `v1_hp1`, `v1_hp2`, `v2_hp1`, `v2_hp2`
    - Same algorithm (e.g. Linear Regression), 2 hyperparameter sets
5. **Evaluation**
    - Metrics: RMSE, RÂ² Score
    - Visuals: Predicted vs. Actual plots
6. **Carbon Emissions Tracking**
    - Used `codecarbon` to record energy usage during training

---

## ğŸ“¦ Dataset Handling (IMPORTANT)

The original `athletes.csv` exceeds GitHub's 25MB upload limit.

### ğŸ”½ Option 1: Download from Cloud  
[Download athletes.csv](https://your-link-to-cloud-storage.com) and place it in your working directory.

### ğŸ’¡ Option 2: Use Compressed Version  
If using `athletes_data.zip`, extract it or read it directly using:

```python
import pandas as pd
import zipfile

with zipfile.ZipFile("athletes_data.zip") as z:
    with z.open("athletes.csv") as f:
        df = pd.read_csv(f)
